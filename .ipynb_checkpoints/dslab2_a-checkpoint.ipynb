{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and EDA of Goodreads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents \n",
    "<ol start=\"0\">\n",
    "<li> Learning Goals </li>\n",
    "<li> Loading and Cleaning with Pandas</li>\n",
    "<li> Asking Questions?  </li>\n",
    "<li> Parsing and Completing the Dataframe  </li>\n",
    "<li> EDA  </li>\n",
    "<li> Determining the Best Books  </li>\n",
    "<li>Trends in Popularity of Genres </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "About 6000 odd \"best books\" were fetched and parsed from [Goodreads](https://www.goodreads.com). The \"bestness\" of these books came from a proprietary formula used by Goodreads and published as a list on their web site.\n",
    "We parsed the page for each book and saved data from all these pages in a tabular format as a CSV file. In this lab we'll clean and further parse the data.  We'll then do some exploratory data analysis to answer questions about these best books and popular genres.  \n",
    "By the end of this lab, you should be able to:\n",
    "- Load and systematically address missing values, ancoded as `NaN` values in our data set, for example, by removing observations associated with these values.\n",
    "- Parse columns in the dataframe to create new dataframe columns.\n",
    "- Create and interpret visualizations to explore the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic EDA workflow\n",
    "The basic workflow is as follows:\n",
    "\n",
    "1. **Build** a DataFrame from the data (ideally, put all data in this object)\n",
    "2. **Clean** the DataFrame. It should have the following properties:\n",
    "    - Each row describes a single object\n",
    "    - Each column describes a property of that object\n",
    "    - Columns are numeric whenever appropriate\n",
    "    - Columns contain atomic properties that cannot be further decomposed\n",
    "3. Explore **global properties**. Use histograms, scatter plots, and aggregation functions to summarize the data.\n",
    "4. Explore **group properties**. Use groupby and small multiples to compare subsets of the data.\n",
    "\n",
    "This process transforms your data into a format which is easier to work with, gives you a basic overview of the data's properties, and likely generates several questions for you to followup in subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Cleaning with Pandas \n",
    "Read in the `goodreads.csv` file, examine the data, and do any necessary data cleaning. \n",
    "\n",
    "Here is a description of the columns (in order) present in this csv file:\n",
    "\n",
    "```\n",
    "rating: the average rating on a 1-5 scale achieved by the book\n",
    "review_count: the number of Goodreads users who reviewed this book\n",
    "isbn: the ISBN code for the book\n",
    "booktype: an internal Goodreads identifier for the book\n",
    "author_url: the Goodreads (relative) URL for the author of the book\n",
    "year: the year the book was published\n",
    "genre_urls: a string with '|' separated relative URLS of Goodreads genre pages\n",
    "dir: a directory identifier internal to the scraping code\n",
    "rating_count: the number of ratings for this book (this is different from the number of reviews)\n",
    "name: the name of the book\n",
    "```\n",
    "\n",
    "Report all the issues you found with the data and how you resolved them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning: Reading in the data\n",
    "We read in and clean the data from `goodreads.csv`.  Try directly loading the data from file and see what the dataframe look like. What's the problem with naively loading the data as is? You might want to open the CSV file in Excel or your favorite text editor to see how this dataset is formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data into a dataframe\n",
    "data = pd.read_csv(\"data/goodreads.csv\")\n",
    "\n",
    "#Examine the first couple of rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/goodreads.csv\", header=None,\n",
    "               names=[\"rating\", 'review_count', 'isbn', 'booktype','author_url', 'year', 'genre_urls', 'dir','rating_count', 'name'],\n",
    ")\n",
    "#Examine the first couple of rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning: Examing the dataframe - quick checks\n",
    "\n",
    "Examine the dataframe to get a overall sense of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by check the column data types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple more quick sanity checks to perform on the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Come up with a few other important properties of the dataframe to check\n",
    "print(data.shape)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was the data read correctly and values represented as we expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that `review_count` and `rating_counts` are objects instead of ints, and the `year` is a float!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning: Examining the dataframe - a deeper look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond performing checking some quick general properties of the data frame and looking at the first $n$ rows, we can dig a bit deeper into the values being stored. If you haven't already, check to see if there are any missing values in the data frame.\n",
    "\n",
    "Let's see for a column which seemed OK to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a sense of how many missing values there are in the dataframe.\n",
    "np.sum([data.rating.isnull()])\n",
    "# do this for other columns as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to locate where the missing values occur\n",
    "data[data.rating.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now check if any of the other suspicious columns have missing values.  Let's look at `year` and `review_count` first.\n",
    "One thing you can do is to try and convert to the type you expect the column to be. If something goes wrong, it likely means your data are bad.\n",
    "Lets test for missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.year.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning: Dealing with Missing Values\n",
    "How should we interpret 'missing' or 'invalid' values in the data (hint: look at where these values occur)? One approach is to simply exclude them from the dataframe. Is this appropriate for all 'missing' or 'invalid' values? How would you drop these values from the dataframe (hint: is it possible to eliminate just a single entry in your dataframe? Should you eliminate an entire row? Or column?)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Treat the missing or invalid values in your dataframe\n",
    "data = data[data.year.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so we have done some cleaning. What do things look like now? Notice the float has not yet changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(data.year.isnull()))\n",
    "print(np.sum(data.rating_count.isnull())) \n",
    "print(np.sum(data.review_count.isnull())) \n",
    "# How many rows are removed?\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets try to change the data types of rating count and year to integer\n",
    "data.rating_count=data.rating_count.astype(int)\n",
    "data.review_count=data.review_count.astype(int)\n",
    "data.year=data.year.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some of the other colums that should be strings have NaN.\n",
    "data.loc[data.genre_urls.isnull(), 'genre_urls']=\"\"\n",
    "data.loc[data.isbn.isnull(), 'isbn']=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 2: Asking Questions\n",
    "Think of few questions we want to ask and then examine the data and decide if the dataframe contains what you need to address these questions. Answer the following\n",
    "* Which are the best books?\n",
    "* Is finction more popular than fantasy? \n",
    "* Is J K Rowling the highest rated author?\n",
    "* What are the trends in popularity of genres?\n",
    "* Which genre is more popular now vs 100 years ago?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Part 3: Parsing and Completing the Data Frame \n",
    "\n",
    "We will need author and genre to proceed! Parse the `author` column from the author_url and `genres` column from the genre_urls. Keep the `genres` column as a string separated by '|'.\n",
    "Examine an example `author_url` and reason about which sequence of string operations must be performed in order to isolate the author's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the first author_url\n",
    "test_string = data.author_url[0]\n",
    "print(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the author name\n",
    "test_string.split('/')[-1].split('.')[1:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function that accepts an author url and returns the author's name based on your experimentation above\n",
    "def get_author(url):\n",
    "    \n",
    "    name = url.split('/')[-1].split('.')[1:][0]\n",
    "    return name\n",
    "\n",
    "#Apply the get_author function to the 'author_url' column using '.map' \n",
    "#and add a new column 'author' to store the names\n",
    "data['author'] = data.author_url.map(get_author)\n",
    "data.author[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now parse out the genres from `genre_url`.  Like with the authors, we'll assign a new `genres` column to the dataframe.\n",
    "This is a little more complicated because there be more than one genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.genre_urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine some examples of genre_urls\n",
    "#Test out some string operations to isolate the genre name\n",
    "test_genre_string = data.genre_urls[0]\n",
    "print(test_genre_string)\n",
    "\n",
    "genres = test_genre_string.strip().split('|')\n",
    "print(genres)\n",
    "\n",
    "for e in genres:\n",
    "    print(e.split('/')[-1])\n",
    "# \"|\".join(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function that accepts a genre url and returns the genre name based on your experimentation above\n",
    "def split_and_join_genres(url):\n",
    "    genres = url.strip().split('|')\n",
    "    genres = [e.split('/')[-1] for e in genres]\n",
    "    return \"|\".join(genres)\n",
    "\n",
    "data['genres'] = data.genre_urls.map(split_and_join_genres)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function\n",
    "split_and_join_genres(\"\")\n",
    "split_and_join_genres(\"/genres/young-adult|/genres/science-fiction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's pick an author at random so we can see the results of the transformations.  Scroll to see the `author` and `genre` columns that we added to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[data.author == \"Marguerite_Yourcenar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: EDA \n",
    "Before proceeding any further, get to know the dataset using a few \"global property\" visualizations, illustrating histograms with both linear and log scales. Do you find anything interesting or strange? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate histograms using the format data.COLUMN_NAME.hist(bins=YOUR_CHOICE_OF_BIN_SIZE)\n",
    "# If your histograms appear strange or counter-intuitive, make appropriate adjustments in the data and re-visualize.\n",
    "\n",
    "data.review_count.hist(bins=200)\n",
    "plt.xlabel('Number of reviews')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Number of reviews');\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.year, bins=100);\n",
    "plt.xlabel('Year written')\n",
    "plt.ylabel('log(Frequency)')\n",
    "plt.title('Number of books in a year')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It appears that some books were written in negative years!  \n",
    "# Print out the observations that correspond to negative years.  \n",
    "data[data.year < 0].name\n",
    "# What do you notice about these books?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 5:  Determining the Best Books \n",
    "\n",
    "This is an example of an analysis of the \"grouped property\" type.\n",
    "Think of some reasonable definitions of what it could mean to be a \"best book.\" (After all, these are all the best books according to Goodreads)\n",
    "For example, we can determine the \"best book\" by year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using .groupby, we can divide the dataframe into subsets by the values of 'year'.\n",
    "#We can then iterate over these subsets\n",
    "\n",
    "for year, subset in data.groupby('year'):\n",
    "    #Find the best book of the year\n",
    "    bestbook = subset[subset.rating == subset.rating.max()]\n",
    "    if bestbook.shape[0] > 1:\n",
    "        print(year, bestbook.name.values, bestbook.rating.values)\n",
    "    else:\n",
    "        print(year, bestbook.name.values[0], bestbook.rating.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6:  Trends in Popularity of Genres \n",
    "\n",
    "This is an example of an analysis of the \"grouped property\" type.\n",
    "There are a lot of questions you could ask about genres.\n",
    "* Which genre is currently the most popular?\n",
    "* Better, based on our data, what draw conclusions can you draw about the time evolution of the popularity of each genre?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to find the distinct genres in the dataframe. \n",
    "To do this, notice that each string is a pipe (|) separated list of genres. For each string, we ask if the genre is in that pipe separated list.  If it is, we return True, else False \n",
    "**Hint: remember that python sets have unique (non-repeating) items.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the unique genres contained in the dataframe.\n",
    "genres = set()\n",
    "for genre_string in data.genres:\n",
    "    genres.update(genre_string.split('|'))\n",
    "genres = sorted(genres)\n",
    "genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we add a column to the dataframe for each genre? \n",
    "Is this way of representing genre efficient? Allows for easy computation and visualization?\n",
    "Are there other ways to represent genre information in the dataframe that allow for each visualization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a column for each genre\n",
    "for genre in genres:\n",
    "    data[\"genre:\"+genre] = [genre in g.split('|') for g in data.genres]\n",
    "         \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the dataframe explodes horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an \"encoding\" change. Genres are a categorical variable. What we have done is created a  **One Hot Encoding** where we have transformed to a True-False (1-0) encoding, or what is known as an **Indicator** variable. These are used all the time in Machine learning. \n",
    "Now explore some ways to visualize the genres represented in the dataframe. \n",
    "For example, you might ask which is the most represented genre.\n",
    "The highest represented genres are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genreslist = ['genre:'+g for g in genres]\n",
    "dfg = data[genreslist].sum() # True's sum as 1's, and default sum is columnwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg.sort_values(ascending=False).plot(kind = \"bar\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The above histogram looks very clumsy!\n",
    "# so now view less data\n",
    "dfg.sort_values(ascending=False).iloc[0:20].plot(kind = \"bar\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfg.sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the most frequent genres by years. We create a visualization called a  *Small Multiples* plot, which shows the yearly histograms for multiple variables. \n",
    "We limit the visualization to the genres that contain more than 550 books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_wanted=dfg.index[dfg.values > 550]\n",
    "print(genres_wanted.shape)\n",
    "genres_wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each genre, we collect the years for which this genre's column is true and make a set of histograms. We fix our bins and plot the histograms against a grey histogram for the general increase in books in our dataset per year.\n",
    "\n",
    "Here we illustrate using axis matplotlib methods instead of `plt` functions as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=10, ncols=3, figsize=(12, 40), tight_layout=True)\n",
    "bins = np.arange(1950, 2013, 3)\n",
    "for ax, genre in zip(axes.ravel(), genres_wanted):\n",
    "    ax.hist(data[data[genre] == True].year.values, bins=bins, histtype='stepfilled', normed=True, color='r', alpha=.2, ec='none')\n",
    "    ax.hist(data.year, bins=bins, histtype='stepfilled', ec='None', normed=True, zorder=0, color='#cccccc')\n",
    "    \n",
    "    ax.annotate(genre.split(':')[-1], xy=(1955, 3e-2), fontsize=14)\n",
    "    ax.xaxis.set_ticks(np.arange(1950, 2013, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6.1: What can you conclude from the above visualizations?\n",
    "Interprete what is showed above. \n",
    "Pick two or three genres and describe how the popularity of these genres fluctuates with time.  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
